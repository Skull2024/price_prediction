import joblib 
import pandas as pd
import numpy as np
import os
import json
import subprocess
import warnings
from datetime import datetime
import sys
from tabulate import tabulate
from tensorflow.keras.models import load_model

# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import MODELS_FOLDER

# --- –ü–æ–ª—É—á–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ---
if len(sys.argv) < 2:
    print("–û—à–∏–±–∫–∞: –≥–æ—Ä–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–¥–∞–Ω –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç.")
    sys.exit(1)

city = sys.argv[1]
city_model_path = os.path.join(MODELS_FOLDER, city)

# --- –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π ---
available_models = {
    "1": "ridge_model.pkl",
    "2": "elasticnet_model.pkl",
    "3": "random_forest_model.pkl",
    "4": "gradient_boosting_model.pkl",
    "5": "xgboost_model.pkl",
    "6": "lightgbm_model.pkl",
    "7": "catboost_model.pkl",
    "8": "neural_network_model.h5"
}

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ---
has_models = any(os.path.exists(os.path.join(city_model_path, fname)) for fname in available_models.values())
if not has_models:
    print(f"\n‚ùó –î–ª—è –≥–æ—Ä–æ–¥–∞ '{city}' –Ω–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.")
    print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–≤—ã–±–µ—Ä–∏—Ç–µ 'n' –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ).")
    sys.exit(1)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π ---
model_ranking = {}
ranking_file = os.path.join(city_model_path, "model_ranking.json")
if os.path.exists(ranking_file):
    with open(ranking_file, "r", encoding="utf-8") as f:
        model_ranking = json.load(f)

def display_model_ranking():
    print("\nüìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º MAE:")
    for k, v in available_models.items():
        label = v.replace("_model.pkl", "").replace("_", " ").title().replace(".H5", "")
        model_key = v.split("_model")[0].replace(".h5", "").replace("_", " ").title()
        top_tag = ""
        mae_tag = ""
        for rank_name, data in model_ranking.items():
            if rank_name.lower().replace(" ", "") == model_key.lower().replace(" ", ""):
                top_tag = f" (–¢–æ–ø {data['rank']}"
                mae_tag = f", MAE: {data['mae']:,.0f})"
                break
        print(f"{k}: {label}{top_tag}{mae_tag if top_tag else ''}")

# –í–Ω–µ—à–Ω–∏–π —Ü–∏–∫–ª –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
while True:
    print("\n–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –∞—Ä–µ–Ω–¥—ã –∂–∏–ª—å—è:")

    while True:
        try:
            square = float(input("–ü–ª–æ—â–∞–¥—å –∫–≤–∞—Ä—Ç–∏—Ä—ã (–≤ –º¬≤): "))
            if not (20 <= square <= 200):
                print("–û—à–∏–±–∫–∞: –¥–æ–ø—É—Å—Ç–∏–º–∞—è –ø–ª–æ—â–∞–¥—å ‚Äî –æ—Ç 20 –¥–æ 200 –º¬≤.")
                continue
            break
        except ValueError:
            print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è –ø–ª–æ—â–∞–¥–∏.")

    while True:
        try:
            room = int(input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç: "))
            if not (1 <= room <= 8):
                print("–û—à–∏–±–∫–∞: –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç ‚Äî –æ—Ç 1 –¥–æ 8.")
                continue
            break
        except ValueError:
            print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–Ω–∞—Ç.")


    print("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –¥–∞—Ç—ã:")
    print("1 - –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É")
    print("2 - –£–∫–∞–∑–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω –º–µ—Å—è—Ü–µ–≤ —Ç–µ–∫—É—â–µ–≥–æ –≥–æ–¥–∞")
    while True:
        date_choice = input("–í–∞—à –≤—ã–±–æ—Ä (1/2): ").strip()
        if date_choice in ["1", "2"]:
            break
        else:
            print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ 1 –∏–ª–∏ 2.")

    dates = []
    if date_choice == "1":
        while True:
            date_str = input("–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É (–≤ —Ñ–æ—Ä–º–∞—Ç–µ –ì–ì–ì–ì-–ú–ú-–î–î): ").strip()
            date = pd.to_datetime(date_str, format="%Y-%m-%d", errors='coerce')
            if pd.isnull(date):
                print("–û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            else:
                dates = [date]
                break
    elif date_choice == "2":
        while True:
            print("–í–≤–µ–¥–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –º–µ—Å—è—Ü–µ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 5 9 –∏–ª–∏ 5-9):")
            range_str = input("–î–∏–∞–ø–∞–∑–æ–Ω –º–µ—Å—è—Ü–µ–≤ (—Ñ–æ—Ä–º–∞—Ç 5 9 –∏–ª–∏ 5-9): ").strip()
            parts = range_str.replace('-', ' ').split()
            if len(parts) != 2:
                print("–û—à–∏–±–∫–∞: —É–∫–∞–∂–∏—Ç–µ –¥–≤–∞ –º–µ—Å—è—Ü–∞.")
                continue
            try:
                start_month, end_month = map(int, parts)
                if not (1 <= start_month <= 12 and 1 <= end_month <= 12 and start_month <= end_month):
                    print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ –º–µ—Å—è—Ü—ã –æ—Ç 1 –¥–æ 12.")
                    continue
                break
            except ValueError:
                print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–∞.")
        year = datetime.now().year
        for month in range(start_month, end_month + 1):
            try:
                dates.append(datetime(year, month, 15))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞—Ç—ã: {e}")

    display_model_ranking()

    while True:
        model_indices_str = input("–í–∞—à –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2,3): ").strip()
        if not model_indices_str:
            print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –Ω–æ–º–µ—Ä.")
            continue
        model_indices = model_indices_str.split(",")
        selected_models = []
        for idx in model_indices:
            filename = available_models.get(idx.strip())
            if filename:
                model_path = os.path.join(city_model_path, filename)
                if os.path.exists(model_path):
                    try:
                        if filename.endswith(".h5"):
                            selected_models.append(load_model(model_path))
                        else:
                            selected_models.append(joblib.load(model_path))
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {filename}: {e}")
                else:
                    print(f"–ú–æ–¥–µ–ª—å {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            else:
                print(f"–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏: {idx.strip()}")
        if not selected_models:
            print("–û—à–∏–±–∫–∞: –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –≤—ã–±—Ä–∞–Ω–∞.")
            continue
        break

    try:
        poly = joblib.load(os.path.join(city_model_path, "polynomial_features.pkl"))
        scaler = joblib.load(os.path.join(city_model_path, "robust_scaler.pkl"))
        qt = joblib.load(os.path.join(city_model_path, "quantile_transformer.pkl"))
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        sys.exit(1)

    new_data = pd.DataFrame()
    for date in dates:
        row = {
            "city": city,
            "square": square,
            "room": room,
            "date": date,
            "year": date.year,
            "month": date.month,
            "day": date.day,
            "weekday": date.weekday(),
        }
        new_data = pd.concat([new_data, pd.DataFrame([row])], ignore_index=True)

    new_data["days_from_start"] = (new_data["date"] - new_data["date"].min()).dt.days
    new_data["room_density"] = new_data["room"] / (new_data["square"] + 1)
    new_data["is_studio"] = (new_data["room"] <= 1).astype(int)

    features_order = [
        "square", "room", "room_density",
        "year", "month", "day", "weekday", "days_from_start"
    ]

    X_num = new_data[features_order]
    X_poly = poly.transform(X_num)
    X_scaled = scaler.transform(X_poly)
    X_final = np.hstack([X_scaled, new_data[["is_studio"]].values])

    predictions = []
    for model in selected_models:
        try:
            preds_trans = model.predict(X_final)
            preds_orig = qt.inverse_transform(np.array(preds_trans).reshape(-1, 1)).flatten()
            predictions.append(preds_orig)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª—å—é: {e}")

    if predictions:
        final_preds = np.mean(predictions, axis=0)
    else:
        print("–û—à–∏–±–∫–∞: –ø—Ä–æ–≥–Ω–æ–∑ –Ω–µ –ø–æ–ª—É—á–µ–Ω.")
        sys.exit(1)

    output = []
    for d, price in zip(new_data["date"], final_preds):
        output.append([d.strftime("%Y-%m-%d"), room, square, city, f"{price:,.0f} ‚Ç∏"])

    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞:")
    print(tabulate(output, headers=["–î–∞—Ç–∞", "–ö–æ–º–Ω–∞—Ç—ã", "–ü–ª–æ—â–∞–¥—å (–º¬≤)", "–ì–æ—Ä–æ–¥", "–ü—Ä–æ–≥–Ω–æ–∑ (‚Ç∏)"], tablefmt="grid"))

    new_data["predicted_price"] = final_preds
    os.makedirs("predictions", exist_ok=True)
    filename = f"predictions/predict_{city}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    try:
        new_data.to_csv(filename, index=False)
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

    while True:
        again = input("\n–•–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å –µ—â—ë –æ–¥–∏–Ω –ø—Ä–æ–≥–Ω–æ–∑? (y/n): ").strip().lower()
        if again in ["y", "n"]:
            break
        else:
            print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ 'y' –∏–ª–∏ 'n'.")
    if again == "y":
        continue
    else:
        sys.exit(0)
